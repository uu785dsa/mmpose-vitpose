import os
import cv2
import pandas as pd
import numpy as np
from mmpose.apis import init_model, inference_topdown
from mmpose.registry import VISUALIZERS
import torch

# ----------------------------
# é…ç½®å‚æ•°
# ----------------------------
config_file = r'configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192.py'
checkpoint_file = r'G:\vitpose\mmpose\td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth'
output_dir = "G:/gait_dataset/newname/001/nm/135-1"
input_dir = output_dir + '/image_crop'

pred_img_dir = os.path.join(output_dir, 'predictions')
os.makedirs(pred_img_dir, exist_ok=True)

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'

keypoint_names = [
    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
    'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
    'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
]

# ----------------------------
# åˆå§‹åŒ–æ¨¡å‹
# ----------------------------
print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
model = init_model(config_file, checkpoint_file, device=device)
visualizer = VISUALIZERS.build(
    dict(
        type='PoseLocalVisualizer',
        name='visualizer',
        save_dir=pred_img_dir
    )
)
visualizer.set_dataset_meta(model.dataset_meta)

# ----------------------------
# å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼ˆæŒ‰æ•°å­—æ’åºï¼‰
# ----------------------------
results = []

def get_file_number(filename):
    """æå–æ–‡ä»¶åä¸­çš„æ•°å­—ç”¨äºæ’åº"""
    name = os.path.splitext(filename)[0]
    try:
        return int(name)
    except ValueError:
        return float('inf')

# ç­›é€‰å›¾ç‰‡å¹¶æŒ‰æ•°å­—æ’åº
image_files = [f for f in os.listdir(input_dir) 
              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
image_files.sort(key=get_file_number)

for filename in image_files:
    img_path = os.path.join(input_dir, filename)
    print(f"å¤„ç†: {filename}")

    img = cv2.imread(img_path)
    if img is None:
        print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {img_path}")
        continue

    # ç§»é™¤å½’ä¸€åŒ–ç›¸å…³çš„å®½é«˜è·å–ï¼ˆè™½ç„¶ä¿ç•™ä¹Ÿä¸å½±å“ï¼Œä½†å¯ä»¥ç®€åŒ–ï¼‰
    # h, w = img.shape[:2]  # æ­¤è¡Œå¯åˆ é™¤ï¼Œå› ä¸ºä¸å†ç”¨äºå½’ä¸€åŒ–

    try:
        pred_results = inference_topdown(model, img)
    except Exception as e:
        print(f"âŒ æ¨ç†å‡ºé”™ {filename}: {e}")
        continue

    if len(pred_results) == 0:
        print(f"âš ï¸ æœªæ£€æµ‹åˆ°å§¿æ€: {filename}")
        row = {'image_name': f"{output_dir}/{filename}"}
        for name in keypoint_names:
            row[f'{name}_x'] = pd.NA
            row[f'{name}_y'] = pd.NA
            row[f'{name}_conf'] = pd.NA
        results.append(row)
        continue

    pose_result = pred_results[0]
    keypoints = pose_result.pred_instances.keypoints[0]  # (17, 2) åŸå§‹åƒç´ åæ ‡
    keypoint_scores = pose_result.pred_instances.keypoint_scores[0]  # (17,)

    # ç§»é™¤å½’ä¸€åŒ–æ“ä½œï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åæ ‡
    # åŸä»£ç ï¼šx_norm = keypoints[:, 0] / w
    # åŸä»£ç ï¼šy_norm = keypoints[:, 1] / h

    row = {'image_name': f"{output_dir}/{filename}"}
    for i, name in enumerate(keypoint_names):
        # ç›´æ¥ä½¿ç”¨keypointsçš„åŸå§‹å€¼ï¼ˆåƒç´ åæ ‡ï¼‰
        row[f'{name}_x'] = keypoints[i, 0]  # åŸå§‹xåƒç´ åæ ‡
        row[f'{name}_y'] = keypoints[i, 1]  # åŸå§‹yåƒç´ åæ ‡
        row[f'{name}_conf'] = float(keypoint_scores[i])
    results.append(row)

    # å¯è§†åŒ–ä»£ç ï¼ˆå¯é€‰ï¼‰
    visualizer.add_datasample(
        name='result',
        image=img,
        data_sample=pose_result,
        draw_gt=False,
        draw_bbox=False,
        kpt_thr=0.3,
        show=False,
        out_file=os.path.join(pred_img_dir, filename)
    )

# ----------------------------
# ä¿å­˜CSV
# ----------------------------
df = pd.DataFrame(results)
csv_path = os.path.join(output_dir, 'keypoints.csv')
df.to_csv(csv_path, index=False)
print(f"\nâœ… å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³:")
print(f"   ğŸ“Š CSV: {csv_path}")